{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules have been imported\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.preprocessing.image import *\n",
    "from tensorflow.keras.utils import *\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# import pydot\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import *\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from colorama import Fore\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from skimage.io import *\n",
    "%config Completer.use_jedi = False\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "# import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"All modules have been imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading the training Labels:- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(\"trainLabels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35121</th>\n",
       "      <td>44347_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35122</th>\n",
       "      <td>44348_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35123</th>\n",
       "      <td>44348_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35124</th>\n",
       "      <td>44349_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35125</th>\n",
       "      <td>44349_right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35126 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             image  level\n",
       "0          10_left      0\n",
       "1         10_right      0\n",
       "2          13_left      0\n",
       "3         13_right      0\n",
       "4          15_left      1\n",
       "...            ...    ...\n",
       "35121  44347_right      0\n",
       "35122   44348_left      0\n",
       "35123  44348_right      0\n",
       "35124   44349_left      0\n",
       "35125  44349_right      1\n",
       "\n",
       "[35126 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  showing the count of each class:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25810\n",
       "2     5292\n",
       "1     2443\n",
       "3      873\n",
       "4      708\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels['level'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### showing the list of images present in the training dataset:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for dirname, _, filenames in os.walk('train/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the Distribution of each class Labels:-\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='level'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Printing the Distribution of each class Labels:-\")\n",
    "sns.set_style('darkgrid')\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "sns.barplot(x=train_labels.level.unique(),y=train_labels.level.value_counts(),palette='Blues_r',ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_series = pd.Series(train_labels['level'])\n",
    "one_hot = pd.get_dummies(targets_series, sparse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:-\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "5    2\n",
       "6    4\n",
       "7    4\n",
       "8    0\n",
       "9    1\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Labels:-')\n",
    "targets_series[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After One Hot Representation:-\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4\n",
       "0  1  0  0  0  0\n",
       "1  1  0  0  0  0\n",
       "2  1  0  0  0  0\n",
       "3  1  0  0  0  0\n",
       "4  0  1  0  0  0\n",
       "5  0  0  1  0  0\n",
       "6  0  0  0  0  1\n",
       "7  0  0  0  0  1\n",
       "8  1  0  0  0  0\n",
       "9  0  1  0  0  0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"After One Hot Representation:-\")\n",
    "one_hot[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets take a look at the array containing just the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 2, 4, 4, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_labels = np.asarray(one_hot)\n",
    "one_hot_labelsY = np.asarray(targets_series)\n",
    "one_hot_labelsY[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Load the labels from the CSV file\n",
    "train_labels = pd.read_csv('trainLabels.csv')\n",
    "\n",
    "# Create the subfolders\n",
    "for i in range(5):\n",
    "    os.makedirs(str(i), exist_ok=True)\n",
    "\n",
    "# Move the images to the appropriate subfolders\n",
    "try:\n",
    "    for index, row in train_labels.iterrows():\n",
    "        image_file = row['image']\n",
    "        image_file=image_file+\".jpeg\"\n",
    "        label = row['level']\n",
    "        shutil.move(image_file, str(label))\n",
    "else:\n",
    "    pass\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1964 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "        [[[3.5539708e-01, 3.0049512e-01, 1.9853434e-01],\n",
       "          [3.5871130e-01, 2.9826376e-01, 2.0739414e-01],\n",
       "          [3.6202550e-01, 2.9535884e-01, 2.1940978e-01],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[3.5474098e-01, 2.9983902e-01, 1.9787823e-01],\n",
       "          [3.5805520e-01, 2.9957595e-01, 2.0476972e-01],\n",
       "          [3.6136940e-01, 2.9470274e-01, 2.1744147e-01],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[3.5408488e-01, 2.9918292e-01, 1.9722213e-01],\n",
       "          [3.5739911e-01, 3.0088818e-01, 2.0214529e-01],\n",
       "          [3.6071327e-01, 2.9425976e-01, 2.1540211e-01],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "        [[[4.9120089e-01, 3.3574778e-01, 2.1518390e-01],\n",
       "          [4.9821368e-01, 3.2555997e-01, 2.1179961e-01],\n",
       "          [5.1548398e-01, 3.3246812e-01, 2.1525367e-01],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[4.8356155e-01, 3.2564446e-01, 2.1568629e-01],\n",
       "          [4.9378699e-01, 3.3186862e-01, 2.1389085e-01],\n",
       "          [5.0467891e-01, 3.2814607e-01, 2.1309265e-01],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[4.7491744e-01, 3.1051728e-01, 2.1568629e-01],\n",
       "          [4.8873371e-01, 3.3469576e-01, 2.1568629e-01],\n",
       "          [4.9637306e-01, 3.2798952e-01, 2.1259782e-01],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [9.7893808e-06, 2.9368144e-05, 1.9578762e-05],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [2.1708149e-03, 6.5124440e-03, 4.3416298e-03],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [4.3318402e-03, 1.2995521e-02, 9.0739513e-03],\n",
       "          [8.7777246e-04, 2.6333174e-03, 1.7555449e-03],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[2.3787324e-01, 1.8297128e-01, 3.9215688e-02],\n",
       "          [2.3225975e-01, 1.7735779e-01, 3.9215688e-02],\n",
       "          [2.3846202e-01, 1.8356006e-01, 4.6305146e-02],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[2.4559763e-01, 1.7793180e-01, 3.7088379e-02],\n",
       "          [2.3785684e-01, 1.8295486e-01, 3.9215688e-02],\n",
       "          [2.3224333e-01, 1.7734137e-01, 3.9215688e-02],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[2.4997613e-01, 1.7556188e-01, 3.7302680e-02],\n",
       "          [2.4557300e-01, 1.7795643e-01, 3.7096586e-02],\n",
       "          [2.3784040e-01, 1.8293844e-01, 3.9215688e-02],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [2.0535772e-01, 1.6222046e-01, 3.6730260e-02],\n",
       "          [2.0118037e-01, 1.5804312e-01, 3.2552909e-02],\n",
       "          [1.9633423e-01, 1.5319696e-01, 2.7706767e-02]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [2.0721692e-01, 1.6407967e-01, 3.9215688e-02],\n",
       "          [2.0534952e-01, 1.6221227e-01, 3.6722049e-02],\n",
       "          [2.0116395e-01, 1.5802668e-01, 3.2536488e-02]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [2.0161985e-01, 1.5848260e-01, 3.9215688e-02],\n",
       "          [2.0723335e-01, 1.6409609e-01, 3.9215688e-02],\n",
       "          [2.0534131e-01, 1.6220404e-01, 3.6713842e-02]]],\n",
       " \n",
       " \n",
       "        [[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[4.2662600e-01, 4.6016559e-01, 2.4004072e-01],\n",
       "          [4.1514537e-01, 4.4300196e-01, 2.3813382e-01],\n",
       "          [4.1430691e-01, 4.2595333e-01, 2.2352943e-01],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[4.2074209e-01, 4.5575264e-01, 2.4592461e-01],\n",
       "          [4.1073245e-01, 4.3123421e-01, 2.2930801e-01],\n",
       "          [4.2607465e-01, 4.3036625e-01, 2.2352943e-01],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[4.1604564e-01, 4.4540271e-01, 2.3993436e-01],\n",
       "          [4.1190615e-01, 4.2505306e-01, 2.2352943e-01],\n",
       "          [4.3784243e-01, 4.3477914e-01, 2.2352943e-01],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "        [[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32),\n",
       " array([[0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.]], dtype=float32))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                  fill_mode='nearest')\n",
    "training_set = train_datagen.flow_from_directory('/Users/siddharthachakraborty/Desktop/Trainings/ **Projects** /Computer Vision/Diabetic Retinopathy/Diabetic_Retinopathy/data/train 3',\n",
    "#                                                  target_size = (64, 64),\n",
    "                                                 target_size=(224,224),\n",
    "#                                                  batch_size = 32,\n",
    "                                                 batch_size = 100,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                shuffle=True)\n",
    "\n",
    "training_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets just verify one of the images from the numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-85b6a3189bf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#681 > Try some other number too\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "plt.imshow(x_train[5]/255) #681 > Try some other number too \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35126/35126 [00:04<00:00, 7099.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_test=[]\n",
    "#this is a OpenCV implementation\n",
    "i = 0 \n",
    "for f, breed in tqdm(train_labels.values):\n",
    "    if type(cv2.imread('/storage/test/{}.jpeg'.format(f)))==type(None):\n",
    "        continue\n",
    "    else:\n",
    "        img = cv2.imread('/storage/test/{}.jpeg'.format(f))\n",
    "        label = one_hot_labels[i]\n",
    "        x_test.append(cv2.resize(img, (im_size1, im_size2)))\n",
    "        i += 1\n",
    "np.save('x_test',x_test)\n",
    "print('Done')\n",
    "\n",
    "# i=0\n",
    "# for f, breed in tqdm(test_labels.values):\n",
    "#     try:\n",
    "#         img = image.load_img(('train/{}.jpeg'.format(f)), target_size=(786, 786))\n",
    "#         arr = image.img_to_array(img)\n",
    "#         label = one_hot_labelsY[i]\n",
    "#         x_train.append(arr)\n",
    "#         y_train.append(label)\n",
    "#         i += 1 \n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "# test_set = test_datagen.flow_from_directory('/Users/siddharthachakraborty/Desktop/Deep Learning Project Work Wipro/Diabetic Retinopathy/LATEST DATASET from Bikash/datasets/val',\n",
    "# #                                             target_size = (64, 64),\n",
    "#                                             target_size= (224, 224),\n",
    "#                                             batch_size=100,\n",
    "# #                                             batch_size = 32,\n",
    "#                                             class_mode = 'categorical',\n",
    "#                                            shuffle=True)\n",
    "# test_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2. Part 2 - Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# follow from line 15 of the \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dnn_model=Sequential()\n",
    "# ##. https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
    "# dnn_model.add(Dense(32, kernel_initializer = 'uniform', activation = 'relu' ))\n",
    "# ## https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization\n",
    "# dnn_model.add(BatchNormalization())\n",
    "# ## https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout\n",
    "# dnn_model.add(Dropout(0.2))\n",
    "# dnn_model.build(64,64)\n",
    "# dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"conv2d_9\" (type Conv2D).\n\nNegative dimension size caused by subtracting 3 from 2 for '{{node conv2d_9/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_9/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,32], [3,3,32,32].\n\nCall arguments received by layer \"conv2d_9\" (type Conv2D):\n  â€¢ inputs=tf.Tensor(shape=(None, 2, 2, 32), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-809c64a2253a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m## Adding a fifth    cConvolutional Layer.,;;::--\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## only difference is that while creating the second CNN.,; we do not need/have to give the input_shape as an input.,;; since.,;; it is only required for the very fiorst time.!!.,;;,;;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1961\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1962\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1965\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"conv2d_9\" (type Conv2D).\n\nNegative dimension size caused by subtracting 3 from 2 for '{{node conv2d_9/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_9/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,32], [3,3,32,32].\n\nCall arguments received by layer \"conv2d_9\" (type Conv2D):\n  â€¢ inputs=tf.Tensor(shape=(None, 2, 2, 32), dtype=float32)"
     ]
    }
   ],
   "source": [
    "'''Initialise the CNN.,;;'''\n",
    "\n",
    "cnn =  tf.keras.models.Sequential() ## helps in creating an AA; as a sequence of layers;.,\n",
    "\n",
    "'''Covolution.,::--;;'''\n",
    "\n",
    "## The convolutional layer will be an object of the / a certain class; which is.,;; the Conv2D class; --> this asks the Dense class --> to build a fully connected layer; belongs to the same module,i.e.,;/or.,; \"Layers\" module from the Keras library.,;;..,,,,..from this time; TensorFlow;2.0.,;;\n",
    "cnn.add(tf.keras.layers.Conv2D( filters=32, kernel_size=3, activation='relu', input_shape=[64,64,3] )) ## Only change that we need to change is that; \"activation\" parameter;., which obviously corresponds to the Activation Function.,;; because based on a general rule; as long as; we haven't reached the output layer; we would rather wanna get a \"rectifier\" activation function.,; .!!.,; --> and for this one; we will choose the \"RELU\" parameter name.,; which corresponds to the.,; rectifier activation functionm.,.!!.,; \n",
    "## input_shape being = (64,64,3)## Ssince it is a coloured image; and for b&w images.,; it should have been.,;:-:-  (64,64,1).!!.,;\n",
    "## the kernel size is considered as 3*3;., hence given the respective parameter input values.,;\n",
    "\n",
    "'''Pooling:-'''\n",
    "\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2)) ## the parameters to be mentioned within the \"MaxPool2D()\" class.,; are :- <1,.> the pooled feature map size.,; ,.., and the <2,.> is the stride size/lenth/values(1).!!.,; \n",
    "## Well.,; for this we need to call the add method;., becuase.,;/since.,; we are adding our pooling layers to our convolutional layers.,;;..,, as next step in the/this \"sequence of layers.,;;.,;;\"\n",
    "## Note that.,; Asa the new object or the instance of a class is added; calleed as the maxpool2D class.,; which belongs to previously/above., mentioned layers module.,;\n",
    "\n",
    "\n",
    "## Adding a second cConvolutional Layer.,;;::--\n",
    "cnn.add(tf.keras.layers.Conv2D( filters=32, kernel_size=3, activation='relu'  )) ## only difference is that while creating the second CNN.,; we do not need/have to give the input_shape as an input.,;; since.,;; it is only required for the very fiorst time.!!.,;;,;;\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "## Adding a third cConvolutional Layer.,;;::--\n",
    "cnn.add(tf.keras.layers.Conv2D( filters=32, kernel_size=3, activation='relu'  )) ## only difference is that while creating the second CNN.,; we do not need/have to give the input_shape as an input.,;; since.,;; it is only required for the very fiorst time.!!.,;;,;;\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "## Adding a fourth cConvolutional Layer.,;;::--\n",
    "cnn.add(tf.keras.layers.Conv2D( filters=32, kernel_size=3, activation='relu'  )) ## only difference is that while creating the second CNN.,; we do not need/have to give the input_shape as an input.,;; since.,;; it is only required for the very fiorst time.!!.,;;,;;\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "## Adding a fifth    cConvolutional Layer.,;;::--\n",
    "cnn.add(tf.keras.layers.Conv2D( filters=32, kernel_size=3, activation='relu'  )) ## only difference is that while creating the second CNN.,; we do not need/have to give the input_shape as an input.,;; since.,;; it is only required for the very fiorst time.!!.,;;,;;\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "## Adding a sixth cConvolutional Layer.,;;::--\n",
    "cnn.add(tf.keras.layers.Conv2D( filters=32, kernel_size=3, activation='relu'  )) ## only difference is that while creating the second CNN.,; we do not need/have to give the input_shape as an input.,;; since.,;; it is only required for the very fiorst time.!!.,;;,;;\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "## Adding a seventh!!..,,;; cConvolutional Layer.,;;::--\n",
    "cnn.add(tf.keras.layers.Conv2D( filters=32, kernel_size=3, activation='relu'  )) ## only difference is that while creating the second CNN.,; we do not need/have to give the input_shape as an input.,;; since.,;; it is only required for the very fiorst time.!!.,;;,;;\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "## Adding an eighth cConvolutional Layer.,;;::--\n",
    "cnn.add(tf.keras.layers.Conv2D( filters=32, kernel_size=3, activation='relu'  )) ## only difference is that while creating the second CNN.,; we do not need/have to give the input_shape as an input.,;; since.,;; it is only required for the very fiorst time.!!.,;;,;;\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "## Adding a ninth cConvolutional Layer.,;;::--\n",
    "cnn.add(tf.keras.layers.Conv2D( filters=32, kernel_size=3, activation='relu'  )) ## only difference is that while creating the second CNN.,; we do not need/have to give the input_shape as an input.,;; since.,;; it is only required for the very fiorst time.!!.,;;,;;\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "## Adding a tenth.!!.,;!!..,,;; cConvolutional Layer.,;;::--\n",
    "cnn.add(tf.keras.layers.Conv2D( filters=32, kernel_size=3, activation='relu'  )) ## only difference is that while creating the second CNN.,; we do not need/have to give the input_shape as an input.,;; since.,;; it is only required for the very fiorst time.!!.,;;,;;\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "'''Flattening.,::--'''\n",
    "cnn.add(tf.keras.layers.Flatten())## done using a class called Flatten() class.,;,.!!.,;;\n",
    "\n",
    "'''Step 4.,:-:- Full Connection.,;,.!!.,;;'''\n",
    "cnn.add(tf.keras.layers.Dense(units=128,activation='relu' ))## So the first/1st parameter.,; contains the number of hidden neurons that you will have into this newly fully connected layer.,;  2nd is the activation function\n",
    "## Therefore;., now we are creating/add a new layer;., which is a fully connected layer.,;; and it still belongs to the tf.keras layers; \n",
    "\n",
    "'''Step 5.,;;::--'''\n",
    "'''Output Layer'''\n",
    "cnn.add(tf.keras.layers.Dense(units=5,activation='sigmoid' )) ## since binary classification hence we only need 5 Neural Networks ..,,;;;;..,,!!..,,;;;;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
